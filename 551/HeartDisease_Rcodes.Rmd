---
title: "551 Project Rcodes"
author: "Chen Xie, Xinye Jiang, Xun Wang"
date: "2019/4/29"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,message=FALSE,warning=FALSE)
```

## Data Exploration

### Tables

```{r}
## Libraries:
library(coda); 
library(ggplot2);library(gbm);library(GGally)
library(dplyr);library(tidyr)
library(knitr);library(kableExtra)

## Read Data:
h = read.csv("heart.csv")
h$sex=as.factor(h$sex)
h$cp=as.factor(h$cp)
h$fbs = as.factor(h$fbs)
h$restecg = as.factor(h$restecg)
h$exang = as.factor(h$exang)
h$slope = as.factor(h$slope)
h$ca = as.factor(h$ca)
h$thal = as.factor(h$thal)

## The response variable
#h$target = as.factor(h$target)
```
 
 
```{r,out.height='80%',out.width='80%'}
## Insert figure of description table of variables:
knitr::include_graphics(c("dataset.png"))
```

```{r}
## Generate Summary table for continuous variables:
do.call(cbind, lapply(h[,c(1,4,5,8,10)],summary)) %>%
  kable("latex", booktabs = T,
        caption='Summary of Continous Variables') %>%
  kable_styling(latex_options = "striped")

## Genrate Summary table for categorical variables:
tbl1<-tibble('target'=c('0: 138','1: 165','','',''),
             'sex'=c('female: 96','male: 207','','',''), 
             'cp'=c('0: 143', '1: 50','2: 87','3: 23',''), 
             'fbs'=c('0: 258', '1: 45 ','','',''),
             'restecg'=c('0: 147', '1: 152','2: 4','',''),
             'exang'=c('0: 204', '1: 99','','',''),
             'slope'=c('0: 21','1: 140', '2: 142','',''),
             'ca'=c('0: 175','1: 65','2: 38','3: 20','4: 5'),
             'thal'=c('0: 2','1: 18','2: 166','3: 117',''))
tbl1 %>%
  kable("latex", booktabs = T,
        caption = 'Summary of Categorical Variables') %>%
  kable_styling() 
```


### Scatterplot

```{r}
## Pair plot including scatterplot, correation, histograms of continuous variables:
## png("pairs.png")
h_pairs=ggpairs(h[c(1,4,5,8,10)],axisLabels = "none",
        upper = list(continuous = "points", combo = "dot"),
        lower = list(continuous = "cor", combo = "dot"),
        diag = list(continuous = "barDiag"),
        title='Pairwise scatterplots and histogram of numeric variables.') + 
  theme_bw()
h_pairs
## dev.off()
```

### barcharts

```{r}
## Barcharst of categorical variables by the response varaibles(target):
bp1<-ggplot(data=as.data.frame(table(h$target,h$sex)), aes(x=Var2, y=Freq, fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='sex', y='Frequency',fill='target',title='Barchart of sex')+
  theme_minimal()
bp2<-ggplot(data=as.data.frame(table(h$target,h$cp)), aes(x=Var2, y=Freq, fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='cp', y='Frequency',fill='target',title='Barchart of cp')+
  theme_minimal()
bp3<-ggplot(data=as.data.frame(table(h$target,h$fbs)), aes(x=Var2, y=Freq, fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='fbs', y='Frequency',fill='target',title='Barchart of fbs')+
  theme_minimal()
bp4<-ggplot(data=as.data.frame(table(h$target,h$restecg)), aes(x=Var2, y=Freq, fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='restecg', y='Frequency',fill='target',title='Barchart of restecg')+
  theme_minimal()
bp5<-ggplot(data=as.data.frame(table(h$target,h$exang)), aes(x=Var2, y=Freq, fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='exang', y='Frequency',fill='target',title='Barchart of exang')+
  theme_minimal()
bp6<-ggplot(data=as.data.frame(table(h$target,h$slope)), aes(x=Var2, y=Freq, fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='slope', y='Frequency',fill='target',title='Barchart of slope')+
  theme_minimal()
bp7<-ggplot(data=as.data.frame(table(h$target,h$ca)), aes(x=Var2, y=Freq, fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='ca', y='Frequency',fill='target',title='Barchart of ca')+
  theme_minimal()
bp8<-ggplot(data=as.data.frame(table(h$target,h$thal)), aes(x=Var2, y=Freq, fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='thal', y='Frequency',fill='target',title='Barchart of thal')+
  theme_minimal()

bp9<-ggplot(data=as.data.frame(table(h$target)), aes(x=Var1, y=Freq,fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=2.5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='target', y='Frequency',fill='target',title='Barchart of target')+
  theme_minimal()

## png("barchart.png")
grid.arrange(bp9,bp1,bp2,bp3,bp4,bp5,bp6,bp7,bp8, nrow = 3)
## dev.off()


## png("response.png")
ggplot(data=as.data.frame(table(h$target)), aes(x=Var1, y=Freq,fill=Var1)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Freq), vjust=1.6, color="black",
            position = position_dodge(0.9), size=5)+
  scale_fill_brewer(palette="Paired")+
  labs(x='target', y='Frequency',fill='target',title='Barchart of target')+
  theme_minimal()
## dev.off()
```

### boxplot

```{r}
## Generate boxplots of continuous variables by target(response):
p1=ggplot(h, aes(x=target,y=age,color=target)) +
  geom_boxplot(outlier.colour="black", outlier.shape=10,outlier.size=2, notch=FALSE)+
  ggtitle("Boxplot of age")+
  scale_color_manual(values=c("#E69F00", "#56B4E9"))
p2=ggplot(h, aes(y=trestbps,x=target,color=target)) +
  geom_boxplot(outlier.colour="black", outlier.shape=10,outlier.size=2, notch=FALSE)+
  ggtitle("Boxplot of trestbps")+
  scale_color_manual(values=c("#E69F00", "#56B4E9"))
p3=ggplot(h, aes(y=chol,x=target,color=target)) +
  geom_boxplot(outlier.colour="black", outlier.shape=10,outlier.size=2, notch=FALSE)+
  ggtitle("Boxplot of chol")+
  scale_color_manual(values=c("#E69F00", "#56B4E9"))
p4=ggplot(h, aes(y=thalach,x=target,color=target)) +
  geom_boxplot(outlier.colour="black", outlier.shape=10,outlier.size=2, notch=FALSE)+
  ggtitle("Boxplot of thalach")+
  scale_color_manual(values=c("#E69F00", "#56B4E9"))
p5=ggplot(h, aes(y=oldpeak,x=target,color=target)) +
  geom_boxplot(outlier.colour="black", outlier.shape=10,outlier.size=2, notch=FALSE)+
  ggtitle("Boxplot of aldpeak")+
  scale_color_manual(values=c("#E69F00", "#56B4E9"))

## png("boxplot.png")
grid.arrange(p1, p2, p3,p4,p5, nrow = 2)
## dev.off()
```


```{r}
## Generate dummy variables for categorical data:
H = model.matrix(target~., data=h)

## Randomly split training and testing test:
set.seed(3)
ind = sample(1:303, 273, replace=F)
Xtrain = H[ind,]
Xtest = H[-ind,]
ytrain = h[ind,14]
ytest = h[-ind,14]
```

## Logistic Regression

### Inference

```{r}
## Fit original logistic regression:
res_original = glm(ytrain~., data=as.data.frame(Xtrain[,-1]), family=binomial(link="logit"))

## Inference: 

### p-values
p1 = summary(res_original)$coefficients[,4]
### estimates fo beta 
beta1 = res_original$coefficients
### estimates with 95% confidence interval for every beta
name = names(beta1)
ci1 = data.frame(lower=beta1, upper= beta1, name=name, mean=beta1, prior="None")

## Formatted Table of summary of the logistic regression 
## including estimate, se,z-value,p-value
data.frame(coef(summary(res_original))) %>%
  kable("latex", booktabs = T,
        caption = 'Summary of Logistic Regression',
        col.names = c('Estimate','Std.Error','z.value','p.value')) %>%
  kable_styling(latex_options = "striped") 
```

### Prediction

```{r}
## Prediction: 
predtest1 = predict(res_original, newdata=as.data.frame(Xtest[,-1]), type="response")
### Confusion matrix of predicted values
table(ytest, 1*(predtest1>0.5))
### Predictive Accuracy
###accuracy1 = mean(predtest1==ytest)
### log loss
logloss1=sum(-log(predtest1[ytest==1]))+sum(-log(1-predtest1[ytest==0]))
### Predictive Sensitivity
sensitivity1 = sum(predtest1*ytest)/sum(ytest)
```



```{r}
## Confusion matrix for prediction result
data.frame(v1=c('Actual: No','Actual: Yes'),v2=c(11, 4),v3=c(4, 11)) %>%
  kable(align = 'r',col.names = c('','Predicted: No','Predicted: Yes'))
```

## Bayesian Logistic Regression with (normal + inverse gamma) prior

```{r}
## Using rstan to draw MCMC posterior samples
library(rstan)
set.seed(551)
dat = list(k=dim(Xtrain)[2], n=dim(Xtrain)[1], x=as.matrix(Xtrain), y=ytrain)
chain2 = stan(file="STATS551_project1.stan", data = dat, iter=2000)
```

### Inference

```{r}
## Extract beta (interested parameters)
params2 = extract(chain2)
beta2 = params2[["beta"]]
```

```{r}
## 95% credible interval based on quantiles of posterior sample
## also get point estimate by mean of posterior sample
ci2 = data.frame(t(apply(beta2, 2, function(x) quantile(x, probs=c(0.025, 0.975)))), name=name, mean=colMeans(beta2), prior="N-IG")
colnames(ci2) = c("lower","upper","name","mean","prior")

## Histograms of posterior samples of beta
## also plot credible interval 
## also check if 0 in the interval
## also compare point estimate of logistic regression to the posterior samples

par(mfrow=c(4,6))
for(i in 1:(dim(beta2)[2])){
  # Histograms
  hist(beta2[,i], 
       main=sprintf("Posterior of beta %s", name[i]), 
       xlab=sprintf("%s", name[i]), xlim=c(min(beta1[i],0,beta2[,i]), max(beta1[i],0,beta2[,i])))
  # point estimate of logistic regression
  abline(v=beta1[i], col="red")
  # line beta=0
  abline(v=0, col="blue")
  # 95% credible interval 
  abline(v=ci2[i,1], col="green", lty=2)
  abline(v=ci2[i,2], col="green", lty=2)
}
```

### Prediction

```{r}
## Prediction:
set.seed(551)
### sample 2000 times from the posterior sample of beta
beta2_sample_ind = sample(1:4000, 5000, replace=T)
### calculate predicted probability based on the predictive sample
prob2 = 1/(1+exp(-as.matrix(Xtest) %*% t(beta2[beta2_sample_ind,])))
### predict the response variable
predtest2 = matrix(rbinom(5000*30, 1, prob=prob2), nrow=30)
### predictive accuracy
### accuracy2_dist = apply(predtest2, 2, function(x) mean(x==ytest))
### point estimation of accuracy2_dist
### accuracy2= mean(accuracy2_dist)
### log loss
logloss2_dist=sapply(1:5000,function(i){sum(-log(prob2[ytest==1,i]))+sum(-log(1-prob2[ytest==0,i]))})
logloss2=mean(logloss2_dist)
### predictive sensitivity
sensitivity2_dist = apply(predtest2, 2, function(x) sum(x*ytest))/sum(ytest)
```

## BayesianLogistic with (normal + exponential + gamma) prior

### choose hyperparameters

```{r}
## a,b: a proposal of hyperparamters
## k: number of predictors, n : number of observations
hyperprior_para_seletion=function(a,b,n,k){
  # Initialize
  mean_data=c()
  set.seed(3)
  # Fake indenpendent data
  X=matrix(rnorm(n*k),nrow=n,ncol=k) 
  # Iteration=1000
  for (i in 1:1000){
    # simulate lambda, variances, beta
    lamb=rgamma(1,shape=a,rate=b)
    sig2=rexp(k,rate=lamb)
    betai=rnorm(k,mean=0,sd=sqrt(sig2))
    # simulate intercept
    alph=rnorm(1,mean=0,sd=2)
    # compute probabilities
    p=exp(alph+X%*%betai)/(1+exp(alph+X%*%betai))
    # simulate Fake y's (response variable)
    y=rbinom(n,size=1,prob=p)
    # compute summary statistic (mean)
    mean_data=c(mean_data,mean(y))
    
    # other options for summarized statistic: e.g., variance
    ##var_data=c(var_data,var(y))
  }
  # return a distribution of summary statistic of fake data for a proposal of (a,b)
  return(mean_data[!is.na(mean_data)])
}

## Compare to the mean of true data and plot
par(mfrow=c(2,2))
hist(hyperprior_para_seletion(a=0.5,b=0.5,n=273,k=22),xlab='mean of generated y',main='alpha=0.5,beta=0.5')
abline(v=mean(ytrain),col='red')
hist(hyperprior_para_seletion(a=5,b=5,n=273,k=22),xlab='mean of generated y',main='alpha=5,beta=5')
abline(v=mean(ytrain),col='red')
hist(hyperprior_para_seletion(a=100,b=1,n=273,k=22),xlab='mean of generated y',main='alpha=100,beta=1')
abline(v=mean(ytrain),col='red')
hist(hyperprior_para_seletion(a=1,b=100,n=273,k=22),xlab='mean of generated y',main='alpha=1,beta=100')
abline(v=mean(ytrain),col='red')
```

### Inference

```{r}
set.seed(551)
## Using rstan to implement MCMC sampling draw posterior sample 
dat = list(k=dim(Xtrain)[2], n=dim(Xtrain)[1], x=as.matrix(Xtrain), y=ytrain)
chain3 = stan(file="STATS551_project2.stan", data = dat, iter=2000)
```

```{r}
## Extract beta and lambda (interested parameters) 
params3 = extract(chain3)
beta3 = params3[["beta"]]
lambda3=params3[['lambda']]

## 95% credible interval based on quantiles of posterior sample
## also get point estimate by mean of posterior sample for NEG prior
ci3 = data.frame(t(apply(beta3, 2, function(x) quantile(x, probs=c(0.025, 0.975)))), name=name, mean=colMeans(beta3), prior="N-E-G")
colnames(ci3) = c("lower","upper","name","mean","prior")
```

```{r}
## Plot of prior and posterior of lambda
## png('lambda.png')
plot(density(lambda3),main="Plot of the posterior distribution of lambda",xlab="lambda")
lines(seq(0,2.7,0.1), dgamma(seq(0,2.7,0.1), 5, 5), col="red")
legend(2, 1.2, c("prior",'posterior'), col=c("red",'black'), lty=c(1,1))
## dev.off()
```

### Prediction

```{r}
set.seed(551)
## Prediction:
### Sampling from posterior sample of beta
beta3_sample_ind = sample(1:4000, 5000, replace=T)
prob3 = 1/(1+exp(-as.matrix(Xtest) %*% t(beta3[beta3_sample_ind,])))
### Generate predicted response
predtest3 = matrix(rbinom(5000*30, 1, prob=prob3), nrow=30)
### predictive accuracy
### accuracy3_dist = apply(predtest3, 2, function(x) mean(x==ytest))
### point estimation of accuracy2_dist
### accuracy3= mean(accuracy3_dist)
### log loss
logloss3_dist=sapply(1:5000,function(i){sum(-log(prob3[ytest==1,i]))+sum(-log(1-prob3[ytest==0,i]))})
logloss3=mean(logloss3_dist)
### predictive sensitivity
sensitivity3_dist = apply(predtest3, 2, function(x) sum(x*ytest))/sum(ytest)
```

## Comparison

### Accuracy

```{r}
# Compare Predictive logloss and plot
## png('logloss.png')
plot(density(logloss3_dist), main="Density of Predictive Logloss", xlab="Logloss", col="blue")
lines(density(logloss2_dist), col="red")
abline(v=logloss1, col="black",lty=2)
abline(v=logloss2, col="red",lty=2)
abline(v=logloss3, col="blue",lty=2)
legend(4.5, 0.18, c("Original","N-IG","N-E-G"), col=c("black","red","blue"), lty=c(1,1,1))
## dev.off()
```

### Sensitivity

```{r}
# Compare Sensitivity and plot
## png('sensitivity.png')
plot(density(sensitivity2_dist), main="Density of Sensitivity", xlab="sensitivity", col="red")
lines(density(sensitivity3_dist), col="blue")
abline(v=sensitivity1, col="black",lty=2)
abline(v=mean(sensitivity2_dist), col="red",lty=2)
abline(v=mean(sensitivity3_dist), col="blue",lty=2)
legend(0.35, 5, c("Original","N-IG","N-E-G"), col=c("black","red","blue"), lty=c(1,1,1))
## dev.off()
```

### Confidence Interval

```{r}
# Compare interval estimation and plot
ci = rbind(ci1,ci2,ci3)

## png('ci.png')
ci %>% # if include intercept
  ggplot( aes(x=name, y=mean, color=prior) ) + 
  geom_point( position = position_dodge(.5) )  +
  geom_errorbar( aes(ymin=lower, ymax=upper), position = position_dodge(.5) ) +
  scale_color_manual( values = c('red', 'orange', '#56B4E9')) +
  coord_flip() +
  theme_bw() + 
  ylab("beta") +
  xlab("")
## dev.off()
```
